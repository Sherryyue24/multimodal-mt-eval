======================================================================
MULTIMODAL MT EVALUATION REPORT
Generated: 2026-01-20 15:38:34
======================================================================

1. CometKiwi (Reference-Free MT Quality)
----------------------------------------------------------------------
   Model: wmt22-cometkiwi-da
   Total Samples: 265

   Mode              Mean Score      Min      Max
   -------------------------------------------
   Text-Only             0.4628   0.1621   0.7307
   Text-Image            0.4795   0.2745   0.7086

   Delta (Text-Image - Text-Only): +0.0167

   Pairwise: Text-Image wins 133, Text-Only wins 128, Ties 6

2. LLM-as-a-Judge (Pairwise Comparison)
----------------------------------------------------------------------
   Judge Model: gpt-4o
   Total Samples: 265

   Winner                  Count       Rate
   --------------------------------------
   Text-Image                169      63.8%
   Text-Only                  90      34.0%
   Tie                         6       2.3%

   Confidence Distribution: {'high': 169, 'low': 18, 'medium': 78}

3. Results by Target Language
----------------------------------------------------------------------
   Language             CometKiwi                 LLM Judge        
                      TO       TI    Delta       TO       TI      TI%
   ------------------------------------------------------------------
   ar_EG          0.3786   0.4432  +0.0645        1        7    77.8%
   bho_IN         0.4838   0.4816  -0.0021        2        7    77.8%
   bn_BD          0.4526   0.4724  +0.0198        0        9   100.0%
   cs_CZ          0.3298   0.3748  +0.0450        5        4    44.4%
   de_DE          0.3791   0.4750  +0.0958        4        5    55.6%
   el_GR          0.4328   0.4427  +0.0098        3        6    66.7%
   et_EE          0.4728   0.4422  -0.0306        2        7    77.8%
   fa_IR          0.3441   0.3988  +0.0547        1        8    88.9%
   hi_IN          0.3845   0.4635  +0.0790        1        7    77.8%
   id_ID          0.4523   0.4957  +0.0434        2        7    77.8%
   is_IS          0.3781   0.4061  +0.0280        1        4    44.4%
   it_IT          0.4762   0.4746  -0.0016        6        3    33.3%
   ja_JP          0.5854   0.6016  +0.0162        2        7    77.8%
   kn_IN          0.5217   0.5285  +0.0067        3        6    66.7%
   ko_KR          0.5236   0.5372  +0.0136        2        7    77.8%
   lt_LT          0.4525   0.5269  +0.0744        2        7    77.8%
   mas_KE         0.4908   0.4929  +0.0021        7        2    22.2%
   mr_IN          0.5174   0.5109  -0.0065        4        5    55.6%
   ro_RO          0.2905   0.5084  +0.2178        2        7    77.8%
   ru_RU          0.4929   0.4842  -0.0088        6        3    33.3%
   sr_Cyrl_RS     0.4880   0.5203  +0.0323        6        3    33.3%
   sr_Latn_RS     0.5133   0.4989  -0.0144        4        5    55.6%
   sv_SE          0.4346   0.4084  -0.0262        3        6    66.7%
   th_TH          0.5464   0.4665  -0.0799        4        5    55.6%
   tr_TR          0.5451   0.4810  -0.0640        4        5    55.6%
   uk_UA          0.4350   0.4295  -0.0055        3        6    66.7%
   vi_VN          0.5479   0.5203  -0.0277        4        5    55.6%
   zh_CN          0.5223   0.5045  -0.0178        6       16    72.7%

======================================================================
KEY FINDINGS
======================================================================

✓ Text-Image outperforms Text-Only on CometKiwi by +0.0167
✓ LLM Judge prefers Text-Image in 63.8% of cases

Top 3 languages where images help most (CometKiwi delta):
   ro_RO: +0.2178
   de_DE: +0.0958
   hi_IN: +0.0790

Top 3 languages where images hurt (CometKiwi delta):
   et_EE: -0.0306
   tr_TR: -0.0640
   th_TH: -0.0799

======================================================================