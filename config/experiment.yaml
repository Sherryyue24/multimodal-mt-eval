# Experiment Configuration - DO NOT CHANGE AFTER Day 2 STARTS
# ⚠️ 一旦开始全量推理，此配置冻结，不允许修改

experiment:
  name: "qwen2vl_multimodal_mt_comparison"
  date: "2026-01-17"
  
# Data Configuration
data:
  # Sample size: 50 or 100 (choose one and freeze)
  num_samples: 50
  random_seed: 42  # Fixed for reproducibility
  source_lang: "en"
  target_lang: "de"
  dataset: "wmt2025_multimodal"
  
  # Paths
  raw_data_dir: "./data/wmt2025_raw"
  debug_samples: "./data/debug_samples.jsonl"  # 3-5 samples for Day 1
  experiment_data: "./data/experiment_data.jsonl"  # Final frozen dataset
  
# Model Configuration
model:
  name: "Qwen/Qwen2-VL-2B-Instruct"
  device: "cuda"  # or "cpu" if no GPU
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  
# Prompts - FROZEN after Day 1
prompts:
  text_only: "Translate the following text from English to German."
  text_image: "Translate the following text from English to German. You can refer to the provided image for context."
  
# Output Paths
outputs:
  text_only: "./outputs/text_only.jsonl"
  text_image: "./outputs/text_image.jsonl"
  merged_results: "./outputs/merged_results.csv"
  
# Evaluation Configuration
evaluation:
  comet:
    model_name: "Unbabel/wmt22-cometkiwi-da"
    batch_size: 8
    
  judge:
    model_name: "gpt-4"  # or other LLM
    temperature: 0.3
    max_tokens: 200
    
# Analysis Paths
analysis:
  comet_scores: "./analysis/comet_scores.csv"
  judge_results: "./analysis/judge_results.csv"
  error_cases: "./analysis/error_cases.csv"
  summary: "./analysis/summary.txt"
